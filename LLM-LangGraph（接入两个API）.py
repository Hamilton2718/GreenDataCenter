# LLM-LangGraph.py
import os
import json
from typing import TypedDict, Annotated, List, Optional
from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, FunctionMessage
from langchain_openai import ChatOpenAI
from langgraph.graph import StateGraph, END


# --- æ¶ˆæ¯ç´¯åŠ å‡½æ•° (ç§»åŠ¨åˆ° DataCenterState å®šä¹‰ä¹‹å‰) ---
def add_messages(left: List[BaseMessage], right: List[BaseMessage]) -> List[BaseMessage]:
    """å°†æ¶ˆæ¯åˆ—è¡¨åˆå¹¶ï¼Œç”¨äºçŠ¶æ€ç®¡ç†"""
    return left + right


# --- 1. å®šä¹‰çŠ¶æ€ (DataCenterState) ---
# å®šä¹‰æ•°æ®ä¸­å¿ƒçŠ¶æ€ï¼Œç”¨äºåœ¨å›¾çš„ä¸åŒèŠ‚ç‚¹ä¹‹é—´ä¼ é€’ä¿¡æ¯
class DataCenterState(TypedDict):
    current_datacenter_load_factor: float  # å½“å‰æ•°æ®ä¸­å¿ƒè´Ÿè½½ç‡ (%)
    predicted_green_energy_ratio: float  # é¢„æµ‹çš„ç»¿ç”µå æ¯” (%)
    grid_carbon_intensity: float  # ç”µç½‘ç¢³æ’æ”¾å¼ºåº¦ (gCO2/kWh)
    target_pue: float  # ç›®æ ‡PUEå€¼
    energy_storage_soc_current_percent: float  # å‚¨èƒ½å½“å‰ç”µé‡ç™¾åˆ†æ¯” (%)
    energy_storage_capacity_mwh: float  # å‚¨èƒ½æ€»å®¹é‡ (MWh)
    grid_stability_index: float  # ç”µç½‘ç¨³å®šæ€§æŒ‡æ•° (0-1ï¼Œ1ä¸ºæœ€ç¨³å®š)
    energy_price_forecast_per_kwh: dict  # ç”µä»·é¢„æµ‹ {å°æ—¶: ä»·æ ¼}

    green_energy_allocation: dict  # ç»¿ç”µåˆ†é…æ–¹æ¡ˆ (ç”±LLMç”Ÿæˆ)
    energy_storage_strategy: dict  # å‚¨èƒ½è°ƒåº¦ç­–ç•¥ (ç”±LLMç”Ÿæˆ)
    migration_path: dict  # è´Ÿè½½è¿ç§»æˆ–å¤–éƒ¨èµ„æºä½¿ç”¨æ–¹æ¡ˆ (ç”±LLMç”Ÿæˆ)
    llm_insights: str  # LLMç”Ÿæˆçš„ç”µåŠ›ç”µå­ä¼˜åŒ–å»ºè®®
    final_plan: dict  # æœ€ç»ˆçš„ç»¼åˆè°ƒåº¦æ–¹æ¡ˆ
    evaluation_report: Optional[str]  # æ–°å¢ï¼šè¯„ä¼°LLMå¯¹æ–¹æ¡ˆçš„è¯„ä¼°æŠ¥å‘Š
    human_feedback: str  # äººå·¥åé¦ˆæ„è§
    human_approved: bool  # æ˜¯å¦é€šè¿‡äººå·¥å®¡æ ¸
    messages: Annotated[list, add_messages]  # è¿™é‡Œå¼•ç”¨äº† add_messages


# 2. åˆå§‹åŒ–ä¸»å¤§æ¨¡å‹ (ä½¿ç”¨ XSimple æä¾›çš„æ¨¡å‹æ¥å£æˆ–å…¼å®¹æ¥å£)
# è¯·æ›¿æ¢ä¸ºå®é™…å¯ç”¨çš„ API Key å’Œ Base URL
# ç¡®ä¿åœ¨è¿è¡Œå‰è®¾ç½® DASHSCOPE_API_KEY ç¯å¢ƒå˜é‡
llm = ChatOpenAI(
    model="qwen-plus",
    api_key=os.getenv("DASHSCOPE_API_KEY"),
    base_url="https://dashscope.aliyuncs.com/compatible-mode/v1"
)

# æ–°å¢ï¼š3. åˆå§‹åŒ–è¯„ä¼°æ¨¡å‹ (ä½¿ç”¨ DeepSeek æ¨¡å‹æ¥å£æˆ–å…¼å®¹æ¥å£)
# è¯·æ›¿æ¢ä¸ºå®é™…å¯ç”¨çš„ API Key å’Œ Base URLï¼Œæ³¨æ„è¿™é‡Œä½¿ç”¨äº† DASHSCOPE_API_KEY2
# ç¡®ä¿åœ¨è¿è¡Œå‰è®¾ç½® DASHSCOPE_API_KEY2 ç¯å¢ƒå˜é‡
eval_llm = ChatOpenAI(
    model="deepseek-v3.2",
    api_key=os.getenv("DASHSCOPE_API_KEY2"),
    base_url="https://dashscope.aliyuncs.com/compatible-mode/v1"
)


# --- èŠ‚ç‚¹å®šä¹‰ ---

# èŠ‚ç‚¹ 1: åŸºç¡€æ•°æ®åˆæ­¥åˆ†æ
def perform_initial_analysis(state: DataCenterState) -> DataCenterState:
    """å¯¹ç»¿ç”µå æ¯”ã€è´Ÿè½½ç‡ã€ç¢³æ’å¼ºåº¦ã€PUEç›®æ ‡ç­‰è¿›è¡Œåˆæ­¥è¯„ä¼°"""
    print("\n[èŠ‚ç‚¹ 1: åŸºç¡€æ•°æ®åˆæ­¥åˆ†æ]")
    green_ratio = state["predicted_green_energy_ratio"]
    load_factor = state["current_datacenter_load_factor"]
    carbon_intensity_grid = state["grid_carbon_intensity"]
    pue_target = state["target_pue"]
    soc = state["energy_storage_soc_current_percent"]
    stability = state["grid_stability_index"]

    # ç®€å•çš„é€»è¾‘åˆ¤æ–­ï¼Œç”Ÿæˆåˆæ­¥è¯„ä¼°å»ºè®®
    analysis_report = f"""
    åˆæ­¥è¯„ä¼°æŠ¥å‘Šï¼š
    - é¢„æµ‹ç»¿ç”µå æ¯”: {green_ratio * 100:.1f}%
    - å½“å‰æ•°æ®ä¸­å¿ƒè´Ÿè½½ç‡: {load_factor * 100:.1f}%
    - ç”µç½‘ç¢³æ’æ”¾å¼ºåº¦: {carbon_intensity_grid} gCO2/kWh
    - ç›®æ ‡ PUE: {pue_target:.2f}
    - å‚¨èƒ½å½“å‰ç”µé‡: {soc:.1f}%
    - ç”µç½‘ç¨³å®šæ€§: {stability:.2f}

    åˆæ­¥ç»“è®ºå’Œå»ºè®®ï¼š
    """
    if green_ratio > 0.6 and load_factor < 0.7 and stability > 0.7:
        analysis_report += "ç³»ç»ŸçŠ¶æ€è‰¯å¥½ï¼Œç»¿ç”µå……è¶³ï¼Œè´Ÿè½½é€‚ä¸­ï¼Œç”µç½‘ç¨³å®šã€‚å»ºè®®ä¼˜å…ˆè€ƒè™‘æœ€å¤§åŒ–ç»¿ç”µæ¶ˆçº³ï¼Œå¹¶ä¼˜åŒ–å‚¨èƒ½å……æ”¾ç”µç­–ç•¥ã€‚"
    elif green_ratio < 0.3 or load_factor > 0.8 or stability < 0.5:
        analysis_report += "ç³»ç»Ÿé¢ä¸´æŒ‘æˆ˜ï¼Œç»¿ç”µå¯èƒ½ä¸è¶³ï¼Œæˆ–è´Ÿè½½è¾ƒé«˜ï¼Œæˆ–ç”µç½‘ä¸ç¨³å®šã€‚éœ€è°¨æ…åˆ¶å®šç­–ç•¥ï¼Œä¼˜å…ˆä¿éšœæ ¸å¿ƒä¸šåŠ¡ï¼Œè€ƒè™‘éœ€æ±‚ä¾§å“åº”æˆ–å¤–éƒ¨èµ„æºã€‚"
    else:
        analysis_report += "ç³»ç»ŸçŠ¶æ€ä¸€èˆ¬ï¼Œéœ€è¦å¹³è¡¡ç»¿ç”µåˆ©ç”¨ã€è´Ÿè½½ç®¡ç†å’Œæˆæœ¬æ•ˆç›Šã€‚å»ºè®®å…³æ³¨ç»†è‡´çš„è°ƒåº¦æ–¹æ¡ˆã€‚"

    state["messages"].append(
        AIMessage(content=f"âœ… å®Œæˆåˆæ­¥æ•°æ®åˆ†æã€‚\n{analysis_report}")
    )
    return state


# èŠ‚ç‚¹ 2: ç»¿ç”µåˆ†é…æ–¹æ¡ˆç”Ÿæˆ
def generate_green_allocation_plan(state: DataCenterState) -> DataCenterState:
    """åŸºäºåˆæ­¥åˆ†æï¼Œåˆ¶å®šç»¿ç”µåˆ†é…æ–¹æ¡ˆ"""
    print("\n[èŠ‚ç‚¹ 2: ç»¿ç”µåˆ†é…æ–¹æ¡ˆç”Ÿæˆ]")
    green_ratio = state["predicted_green_energy_ratio"]
    load_factor = state["current_datacenter_load_factor"]
    pue_target = state["target_pue"]
    carbon_intensity_grid = state["grid_carbon_intensity"]
    soc = state["energy_storage_soc_current_percent"]

    prompt = f"""
    å½“å‰æ•°æ®ä¸­å¿ƒçŠ¶æ€ï¼š
    - é¢„æµ‹ç»¿ç”µå æ¯”: {green_ratio * 100:.1f}%
    - å½“å‰è´Ÿè½½ç‡: {load_factor * 100:.1f}%
    - ç›®æ ‡PUE: {pue_target:.2f}
    - ç”µç½‘ç¢³å¼ºåº¦: {carbon_intensity_grid} gCO2/kWh
    - å‚¨èƒ½å½“å‰SOC: {soc:.1f}%

    è¯·åŸºäºä»¥ä¸Šä¿¡æ¯ï¼Œåˆ¶å®šä¸€ä¸ªç»¿ç”µåˆ†é…æ–¹æ¡ˆã€‚æ–¹æ¡ˆåº”è¯¥è€ƒè™‘ï¼š
    1. ä¼˜å…ˆæ»¡è¶³æ ¸å¿ƒä¸šåŠ¡çš„ç»¿ç”µéœ€æ±‚ã€‚
    2. ä¼˜åŒ–æ¬¡è¦ä¸šåŠ¡å’Œå¯ä¸­æ–­ä¸šåŠ¡çš„ç»¿ç”µä½¿ç”¨ã€‚
    3. è€ƒè™‘åˆ°å‚¨èƒ½çŠ¶æ€ï¼Œæ˜¯å¦åº”å……/æ”¾ç”µã€‚
    4. é™ä½PUEå’Œç¢³æ’æ”¾ã€‚
    5. è¿”å›ä¸€ä¸ªJSONæ ¼å¼çš„æ–¹æ¡ˆï¼ŒåŒ…æ‹¬ï¼š
        - "critical_workloads": {{"core_business_services": "x%", "high_priority_computing": "y%"}}
        - "flexible_workloads": {{"batch_processing": "a%", "data_analytics": "b%"}}
        - "recommendation": "æ–‡æœ¬å½¢å¼çš„è°ƒåº¦å»ºè®®"
    """

    messages = [
        AIMessage(content=f"åˆæ­¥åˆ†æç»“æœå·²å‚è€ƒã€‚"),
        HumanMessage(content=prompt)
    ]

    response = llm.invoke(messages)
    try:
        # å°è¯•è§£æLLMè¿”å›çš„JSON
        allocation = json.loads(response.content)
    except json.JSONDecodeError:
        # å¦‚æœä¸æ˜¯æ ‡å‡†JSONï¼Œåˆ™å°è¯•æå–å»ºè®®ï¼Œå¹¶ç”¨é»˜è®¤ç»“æ„åŒ…è£¹
        # æ³¨æ„ï¼šè¿™é‡Œä¹Ÿéœ€è¦æ›´æ–°é»˜è®¤ç»“æ„çš„JSONå€¼ï¼Œä½¿å…¶ç¬¦åˆLLMç”Ÿæˆé¢„æœŸï¼Œæˆ–è€…è‡³å°‘æ˜¯æœ‰æ•ˆJSON
        allocation = {
            "critical_workloads": {"core_business_services": "50%", "high_priority_computing": "30%"},
            "flexible_workloads": {"batch_processing": "10%", "data_analytics": "10%"},
            "recommendation": response.content  # å°†éJSONå†…å®¹ä½œä¸ºå»ºè®®
        }
        print(f"Warning: LLM did not return perfect JSON. Extracted recommendation: {response.content}")

    # ç¤ºä¾‹å†…éƒ¨é€»è¾‘ï¼Œå¦‚æœLLMè¾“å‡ºç›´æ¥æ˜¯ç™¾åˆ†æ¯”ï¼Œè¿™é‡Œå¯ä»¥å¤„ç†
    # å‡è®¾LLMè¿”å›çš„ allocation å·²ç»æ˜¯å¤„ç†å¥½çš„å­—å…¸
    # ç¤ºä¾‹ä¸­ï¼Œæˆ‘ç›´æ¥ä½¿ç”¨äº†LLMçš„è¾“å‡ºä½œä¸º allocation
    state["green_energy_allocation"] = allocation
    state["messages"].append(
        AIMessage(content="âœ… ç»¿ç”µåˆ†é…æ–¹æ¡ˆåˆ¶å®šå®Œæˆ")
    )
    return state


# èŠ‚ç‚¹ 3: å‚¨èƒ½è°ƒåº¦ä¸è´Ÿè½½è¿ç§»å»ºè®®
def generate_storage_and_migration_plan(state: DataCenterState) -> DataCenterState:
    """ç”Ÿæˆå‚¨èƒ½è°ƒåº¦ç­–ç•¥å’Œè´Ÿè½½è¿ç§»å»ºè®®"""
    print("\n[èŠ‚ç‚¹ 3: å‚¨èƒ½è°ƒåº¦ä¸è´Ÿè½½è¿ç§»å»ºè®®]")
    green_ratio = state["predicted_green_energy_ratio"]
    load_factor = state["current_datacenter_load_factor"]
    soc = state["energy_storage_soc_current_percent"]
    capacity = state["energy_storage_capacity_mwh"]
    grid_stability = state["grid_stability_index"]
    price_forecast = state["energy_price_forecast_per_kwh"]
    current_allocation = json.dumps(state["green_energy_allocation"], indent=2, ensure_ascii=False)

    prompt = f"""
    å½“å‰æ•°æ®ä¸­å¿ƒçŠ¶æ€ï¼š
    - é¢„æµ‹ç»¿ç”µå æ¯”: {green_ratio * 100:.1f}%
    - å½“å‰è´Ÿè½½ç‡: {load_factor * 100:.1f}%
    - å‚¨èƒ½å½“å‰SOC: {soc:.1f}%
    - å‚¨èƒ½æ€»å®¹é‡: {capacity} MWh
    - ç”µç½‘ç¨³å®šæ€§: {grid_stability:.2f}
    - ç”µä»·é¢„æµ‹ (æœªæ¥å‡ å°æ—¶): {json.dumps(price_forecast)}
    - å·²åˆ¶å®šçš„ç»¿ç”µåˆ†é…æ–¹æ¡ˆï¼š
    {current_allocation}

    è¯·æ ¹æ®ä¸Šè¿°ä¿¡æ¯ï¼Œç»¼åˆè€ƒè™‘ç»¿ç”µåˆ†é…æ–¹æ¡ˆï¼Œåˆ¶å®šè¯¦ç»†çš„å‚¨èƒ½è°ƒåº¦ç­–ç•¥å’Œè´Ÿè½½è¿ç§»/å¤–éƒ¨èµ„æºä½¿ç”¨æ–¹æ¡ˆã€‚
    å‚¨èƒ½è°ƒåº¦ç­–ç•¥åº”åŒ…æ‹¬å……æ”¾ç”µçš„æ—¶æœºã€æŒç»­æ—¶é•¿å’Œç›®æ ‡SOCã€‚
    è´Ÿè½½è¿ç§»æ–¹æ¡ˆåº”æŒ‡å‡ºå“ªäº›è´Ÿè½½å¯ä»¥è¿ç§»ï¼Œæˆ–ä½•æ—¶å¯»æ±‚å¤–éƒ¨ç»¿è‰²ç®—åŠ›ã€‚

    è¿”å›ä¸€ä¸ªJSONæ ¼å¼çš„æ–¹æ¡ˆï¼ŒåŒ…æ‹¬ï¼š
    - "energy_storage_strategy": {{"action": "charge/discharge/idle", "duration_hours": X, "target_soc_percent": Y, "reason": "..."}}
    - "migration_or_external_resource_plan": {{"action": "migrate_batch_jobs_to_cloud/seek_external_green_compute/none", "details": "..."}}
    - "overall_recommendation": "ç»¼åˆå»ºè®®æ–‡æœ¬"
    """

    messages = [
        AIMessage(content=f"å·²å‚è€ƒç»¿ç”µåˆ†é…æ–¹æ¡ˆã€‚"),
        HumanMessage(content=prompt)
    ]

    response = llm.invoke(messages)
    try:
        plan = json.loads(response.content)
    except json.JSONDecodeError:
        plan = {
            "energy_storage_strategy": {"action": "idle", "duration_hours": 0, "target_soc_percent": soc,
                                        "reason": "LLM output non-JSON, default to idle."},
            "migration_or_external_resource_plan": {"action": "none", "details": response.content},
            "overall_recommendation": response.content
        }
        print(f"Warning: LLM did not return perfect JSON. Extracted content: {response.content}")

    state["energy_storage_strategy"] = plan.get("energy_storage_strategy", {})
    state["migration_path"] = plan.get("migration_or_external_resource_plan", {})
    state["messages"].append(
        AIMessage(content="âœ… å‚¨èƒ½è°ƒåº¦ä¸è´Ÿè½½è¿ç§»å»ºè®®åˆ¶å®šå®Œæˆ")
    )
    return state


# èŠ‚ç‚¹ 4: LLMç”Ÿæˆç”µåŠ›ç”µå­ä¼˜åŒ–å»ºè®®
def generate_llm_insights_power_electronics(state: DataCenterState) -> DataCenterState:
    """ä»ç”µåŠ›ç”µå­è§’åº¦å¯¹è°ƒåº¦æ–¹æ¡ˆè¿›è¡Œä¼˜åŒ–å’Œæ·±å…¥å»ºè®®"""
    print("\n[èŠ‚ç‚¹ 4: LLMç”Ÿæˆç”µåŠ›ç”µå­ä¼˜åŒ–å»ºè®®]")
    current_green_allocation = json.dumps(state["green_energy_allocation"], indent=2, ensure_ascii=False)
    current_storage_strategy = json.dumps(state["energy_storage_strategy"], indent=2, ensure_ascii=False)
    current_migration_plan = json.dumps(state["migration_path"], indent=2, ensure_ascii=False)
    pue_target = state["target_pue"]

    prompt = f"""
    ä½ æ˜¯ä¸€åèµ„æ·±çš„ç”µåŠ›ç”µå­ä¸“å®¶ï¼Œè¯·åŸºäºä»¥ä¸‹å·²åˆ¶å®šçš„æ•°æ®ä¸­å¿ƒè°ƒåº¦æ–¹æ¡ˆï¼Œä»ç”µåŠ›ç”µå­ã€ç³»ç»Ÿæ•ˆç‡å’Œç»¿è‰²èƒ½æºåˆ©ç”¨æœ€å¤§åŒ–çš„è§’åº¦ï¼Œæä¾›æ·±å…¥çš„ä¼˜åŒ–å»ºè®®ã€‚
    å°¤å…¶å…³æ³¨ä»¥ä¸‹æ–¹é¢ï¼š
    - å¦‚ä½•é€šè¿‡å…ˆè¿›çš„ç”µåŠ›ç”µå­æŠ€æœ¯ï¼ˆå¦‚é«˜æ•ˆç‡æ¨¡å—ã€æ™ºèƒ½æ‹“æ‰‘ã€DC-DCè½¬æ¢å™¨ä¼˜åŒ–ï¼‰è¿›ä¸€æ­¥é™ä½PUEã€‚
    - å‚¨èƒ½ç³»ç»Ÿçš„å…·ä½“è¿è¡Œæ¨¡å¼ã€ç”µæ± ç®¡ç†ç³»ç»Ÿ(BMS)ä¼˜åŒ–ã€åŠŸç‡è½¬æ¢æ•ˆç‡æå‡å»ºè®®ã€‚
    - ç»¿ç”µå¹¶ç½‘ä¸ç³»ç»Ÿç¨³å®šæ€§çš„ç”µåŠ›ç”µå­è§£å†³æ–¹æ¡ˆã€‚
    - åº”å¯¹è´Ÿè½½æ³¢åŠ¨å’Œç»¿ç”µæ³¢åŠ¨çš„æŠ€æœ¯æªæ–½ã€‚

    ç›®æ ‡PUE: {pue_target:.2f}
    å·²åˆ¶å®šç»¿ç”µåˆ†é…æ–¹æ¡ˆï¼š
    {current_green_allocation}
    å·²åˆ¶å®šå‚¨èƒ½è°ƒåº¦ç­–ç•¥ï¼š
    {current_storage_strategy}
    å·²åˆ¶å®šè´Ÿè½½è¿ç§»æ–¹æ¡ˆï¼š
    {current_migration_plan}

    è¯·æä¾›ä¸“ä¸šã€å…·ä½“ã€å¯æ“ä½œçš„ç”µåŠ›ç”µå­ä¼˜åŒ–å»ºè®®ã€‚
    """

    messages = [
        AIMessage(content=f"å·²å‚è€ƒå½“å‰è°ƒåº¦æ–¹æ¡ˆï¼Œå¼€å§‹ç”Ÿæˆç”µåŠ›ç”µå­ä¼˜åŒ–å»ºè®®ã€‚"),
        HumanMessage(content=prompt)
    ]

    response = llm.invoke(messages)
    state["llm_insights"] = response.content
    state["messages"].append(
        AIMessage(content="âœ… å¤§æ¨¡å‹æ´å¯Ÿ (ç”µåŠ›ç”µå­ä¼˜åŒ–è§†è§’) ç”ŸæˆæˆåŠŸ")
    )
    return state


# èŠ‚ç‚¹ 5: æ•´åˆæ‰€æœ‰ç­–ç•¥ï¼Œç”Ÿæˆæœ€ç»ˆè°ƒåº¦æ–¹æ¡ˆ
def integrate_and_finalize_plan(state: DataCenterState) -> DataCenterState:
    """æ•´åˆæ‰€æœ‰ç­–ç•¥å’Œå»ºè®®ï¼Œç”Ÿæˆæœ€ç»ˆè°ƒåº¦æ–¹æ¡ˆ"""
    print("\n[èŠ‚ç‚¹ 5: æ•´åˆæ‰€æœ‰ç­–ç•¥ï¼Œç”Ÿæˆæœ€ç»ˆè°ƒåº¦æ–¹æ¡ˆ]")

    final_plan = {
        "timestamp": "2024-XX-XX HH:MM:SS",  # å®é™…åº”ç”¨ä¸­æ›¿æ¢ä¸ºå½“å‰æ—¶é—´
        "datacenter_status_overview": {
            "predicted_green_energy_ratio": f"{state['predicted_green_energy_ratio'] * 100:.1f}%",
            "current_load_factor": f"{state['current_datacenter_load_factor'] * 100:.1f}%",
            "grid_carbon_intensity": f"{state['grid_carbon_intensity']} gCO2/kWh",
            "target_PUE": f"{state['target_pue']:.2f}",
            "energy_storage_SOC": f"{state['energy_storage_soc_current_percent']:.1f}%",
            "grid_stability": f"{state['grid_stability_index']:.2f}"
        },
        "migration_or_external_resource_plan": state["migration_path"],
        "energy_storage_strategy": state["energy_storage_strategy"],
        "green_energy_allocation_detail": state["green_energy_allocation"],  # ç»¿ç”µåˆ†é…æ–¹æ¡ˆ
        "compliance_and_impact": {
            "pue_target_consideration": f"Current PUE target {state['target_pue']:.2f} needs continuous monitoring.",
            "carbon_reduction_focus": "Emphasis on maximizing green energy use and efficient storage."
        },
        "expert_advice_from_power_electronics_perspective": state["llm_insights"]  # åŒ…å«LLMçš„æ·±åº¦å»ºè®®
    }

    state["final_plan"] = final_plan
    state["messages"].append(
        AIMessage(content="âœ… å®Œæ•´è°ƒåº¦æ–¹æ¡ˆç”ŸæˆæˆåŠŸ")
    )
    return state


# æ–°å¢èŠ‚ç‚¹ 6: æ–¹æ¡ˆè¯„ä¼°èŠ‚ç‚¹ (ä½¿ç”¨ç¬¬äºŒä¸ªAPI DeepSeek)
def evaluate_suggestions_node(state: DataCenterState) -> DataCenterState:
    """ä½¿ç”¨ç¬¬äºŒä¸ªLLMå¯¹å½“å‰ç”Ÿæˆçš„æ–¹æ¡ˆå’Œä¸“å®¶å»ºè®®è¿›è¡Œè¯„ä¼°"""
    print("\n[èŠ‚ç‚¹ 6: è‡ªåŠ¨è¯„ä¼°æ–¹æ¡ˆç¯èŠ‚]")

    final_plan = state.get("final_plan", {})
    green_allocation = final_plan.get("green_energy_allocation_detail", "æ— ç»¿ç”µåˆ†é…æ–¹æ¡ˆ")
    expert_advice = final_plan.get("expert_advice_from_power_electronics_perspective", "æ— ä¸“å®¶å»ºè®®")
    current_state_overview = final_plan.get("datacenter_status_overview", "æ— çŠ¶æ€æ¦‚è§ˆ")
    # è¿™é‡Œçš„ overall_recommendation åº”è¯¥æ¥è‡ª migration_pathï¼Œå¦‚æœç›´æ¥ä» final_plan é‡Œçš„é¡¶å±‚è·å–å¯èƒ½ä¼šå‡ºé”™
    # ä¿®æ­£ä¸ºä» migration_or_external_resource_plan ä¸­è·å–
    migration_plan_details = final_plan.get("migration_or_external_resource_plan", {})
    overall_recommendation = migration_plan_details.get("overall_recommendation", "æ— ç»¼åˆå»ºè®®")
    storage_strategy = final_plan.get("energy_storage_strategy", "æ— å‚¨èƒ½ç­–ç•¥")

    # æ„å»ºè¯„ä¼°æç¤º
    prompt_content = f"""
    ä½ æ˜¯ä¸€ä¸ªä¸¥è°¨çš„è¯„ä¼°ä¸“å®¶ï¼Œè¯·å¯¹ä»¥ä¸‹æ•°æ®ä¸­å¿ƒæ™ºèƒ½è°ƒåº¦æ–¹æ¡ˆå’Œç”µåŠ›ç”µå­ä¸“å®¶å»ºè®®è¿›è¡Œå…¬æ­£ã€å®¢è§‚çš„è¯„ä¼°ã€‚
    è¯„ä¼°è¦ç‚¹ï¼š
    1. æ–¹æ¡ˆçš„åˆç†æ€§ä¸å¯è¡Œæ€§ï¼šæ˜¯å¦å……åˆ†è€ƒè™‘äº†æ‰€æœ‰å…³é”®å› ç´ ï¼ˆå¦‚ç»¿ç”µå æ¯”ã€è´Ÿè½½ã€å‚¨èƒ½ã€PUEç›®æ ‡ã€ç”µç½‘ç¨³å®šæ€§ã€ç”µä»·ç­‰ï¼‰ï¼Ÿ
    2. å»ºè®®çš„æ·±åº¦ä¸å®ç”¨æ€§ï¼šä¸“å®¶å»ºè®®æ˜¯å¦å…·æœ‰å¼€åˆ›æ€§æˆ–æ˜¯å¦åˆ‡å®å¯è¡Œï¼Ÿ
    3. æ½œåœ¨é£é™©ä¸æ”¹è¿›ç‚¹ï¼šæ–¹æ¡ˆæˆ–å»ºè®®å¯èƒ½å­˜åœ¨çš„é£é™©ï¼Œä»¥åŠå¯ä»¥æ”¹è¿›çš„åœ°æ–¹ã€‚
    4. æ•´ä½“è¯„çº§ï¼šç»™å‡ºä¸€ä¸ªç®€è¦çš„æ•´ä½“è¯„ä»·ï¼ˆä¾‹å¦‚ï¼šä¼˜ç§€ã€è‰¯å¥½ã€ä¸€èˆ¬ã€éœ€æ”¹è¿›ï¼‰ï¼Œå¹¶é™„ä¸Šè¯¦ç»†ç†ç”±ã€‚
    5. è¯„ä¼°æŠ¥å‘Šéœ€ç»“æ„åŒ–ï¼ŒåŒ…å«æ€»ç»“å’Œå…·ä½“è¯„ä¼°ç‚¹ã€‚

    --- å¾…è¯„ä¼°çš„æ™ºèƒ½è°ƒåº¦æ–¹æ¡ˆ ---

    æ•°æ®ä¸­å¿ƒå½“å‰çŠ¶æ€æ¦‚è§ˆ: {json.dumps(current_state_overview, indent=2, ensure_ascii=False)}

    è®¡åˆ’çš„ç»¿ç”µåˆ†é…æ–¹æ¡ˆ: {json.dumps(green_allocation, indent=2, ensure_ascii=False)}

    å‚¨èƒ½è°ƒåº¦ç­–ç•¥: {json.dumps(storage_strategy, indent=2, ensure_ascii=False)}

    è´Ÿè½½è¿ç§»/å¤–éƒ¨èµ„æºæ–¹æ¡ˆ: {json.dumps(migration_plan_details, indent=2, ensure_ascii=False)}

    ç”µåŠ›ç”µå­ä¸“å®¶å»ºè®®: {expert_advice}

    --- è¯„ä¼°æŠ¥å‘Š ---
    è¯·è¾“å‡ºä½ çš„è¯„ä¼°æŠ¥å‘Šï¼Œè¦æ±‚è¯¦ç»†ä¸”æœ‰å»ºè®¾æ€§ã€‚
    """

    messages = [
        HumanMessage(content=prompt_content)
    ]

    try:
        response = eval_llm.invoke(messages)
        evaluation_report = response.content
    except Exception as e:
        evaluation_report = f"è¯„ä¼°æ¨¡å‹è°ƒç”¨å¤±è´¥: {e}"
        print(f"Error calling evaluation LLM (DeepSeek): {e}")

    state["evaluation_report"] = evaluation_report
    state["messages"].append(
        AIMessage(content=f"ğŸ“ æ–¹æ¡ˆè‡ªåŠ¨è¯„ä¼°å®Œæˆã€‚è¯„ä¼°æŠ¥å‘Šå·²ç”Ÿæˆã€‚")
    )
    print("è¯„ä¼°æŠ¥å‘Šå·²ç”Ÿæˆã€‚")
    return state


# èŠ‚ç‚¹ 7: äººå·¥å®¡æ ¸èŠ‚ç‚¹ (åŸèŠ‚ç‚¹ 6)
def human_review_node(state: DataCenterState) -> DataCenterState:
    """å±•ç¤ºæœ€ç»ˆæ–¹æ¡ˆã€è‡ªåŠ¨è¯„ä¼°æŠ¥å‘Šå¹¶ç­‰å¾…äººå·¥ç¡®è®¤"""
    print("\n[èŠ‚ç‚¹ 7: äººå·¥å®¡æ ¸ç¯èŠ‚]")
    plan = state["final_plan"]
    evaluation_report = state.get("evaluation_report", "æ— è‡ªåŠ¨è¯„ä¼°æŠ¥å‘Šã€‚")

    print("\n" + "=" * 30 + " äººå·¥å®¡æ ¸ç¯èŠ‚ " + "=" * 30)
    print("å½“å‰ç”Ÿæˆçš„æœ€ç»ˆæ–¹æ¡ˆå¦‚ä¸‹ (æ‘˜è¦)ï¼š")
    print("ç»¿ç”µåˆ†é…:")
    print(json.dumps(plan["green_energy_allocation_detail"], indent=2, ensure_ascii=False))
    print("\nä¸“å®¶å»ºè®®æ‘˜è¦:")
    print(plan["expert_advice_from_power_electronics_perspective"])
    print("\nå‚¨èƒ½è°ƒåº¦ç­–ç•¥æ‘˜è¦:")
    print(json.dumps(plan["energy_storage_strategy"], indent=2, ensure_ascii=False))
    print("\nè´Ÿè½½è¿ç§»/å¤–éƒ¨èµ„æºæ–¹æ¡ˆæ‘˜è¦:")
    print(json.dumps(plan["migration_or_external_resource_plan"], indent=2, ensure_ascii=False))

    print("\n" + "=" * 25 + " è‡ªåŠ¨è¯„ä¼°æŠ¥å‘Š " + "=" * 25)
    print(evaluation_report)
    print("=" * 60)

    # è·å–ç”¨æˆ·è¾“å…¥
    print("\n>>> è¯·å®¡æ ¸æ–¹æ¡ˆ <<<")
    user_input = input("è¾“å…¥ 'y' ç¡®è®¤é€šè¿‡å¹¶ç»“æŸï¼Œæˆ–è¾“å…¥å…·ä½“ä¿®æ”¹æ„è§(ä¾‹å¦‚: 'å¢åŠ å‚¨èƒ½æ”¾ç”µæ¯”ä¾‹') ä»¥é‡æ–°ç”Ÿæˆ: ")

    if user_input.strip().lower() in ['y', 'yes', 'ok', 'é€šè¿‡', '']:
        state["human_approved"] = True
        state["messages"].append(HumanMessage(content="âœ… äººå·¥å®¡æ ¸é€šè¿‡"))
        print(">>> å®¡æ ¸é€šè¿‡ï¼Œæµç¨‹ç»“æŸã€‚")
    else:
        state["human_approved"] = False
        state["human_feedback"] = user_input
        state["messages"].append(HumanMessage(content=f"âŒ äººå·¥å®¡æ ¸æœªé€šè¿‡ï¼Œåé¦ˆæ„è§: {user_input}"))
        print(f">>> æ”¶åˆ°åé¦ˆ: {user_input}ã€‚æ­£åœ¨é‡æ–°è¿›è¡Œæ™ºèƒ½åˆ†æ...")

    return state


# æ„å»ºLangGraphå·¥ä½œæµ
def create_scheduling_graph():
    workflow = StateGraph(DataCenterState)

    # æ·»åŠ èŠ‚ç‚¹
    workflow.add_node("analyze", perform_initial_analysis)
    workflow.add_node("generate_green_allocation", generate_green_allocation_plan)
    workflow.add_node("generate_storage_and_migration", generate_storage_and_migration_plan)
    workflow.add_node("generate_llm_insights", generate_llm_insights_power_electronics)
    workflow.add_node("integrate_and_finalize", integrate_and_finalize_plan)
    workflow.add_node("evaluate", evaluate_suggestions_node)  # æ–°å¢è¯„ä¼°èŠ‚ç‚¹
    workflow.add_node("human_review", human_review_node)

    # æ„å»ºè¾¹
    workflow.set_entry_point("analyze")
    workflow.add_edge("analyze", "generate_green_allocation")
    workflow.add_edge("generate_green_allocation", "generate_storage_and_migration")
    workflow.add_edge("generate_storage_and_migration", "generate_llm_insights")
    workflow.add_edge("generate_llm_insights", "integrate_and_finalize")

    # æ–°å¢è¾¹ï¼šåœ¨æœ€ç»ˆæ–¹æ¡ˆç”Ÿæˆåï¼Œè¿›è¡Œè‡ªåŠ¨è¯„ä¼°
    workflow.add_edge("integrate_and_finalize", "evaluate")

    # ä¿®æ”¹è¾¹ï¼šä»è¯„ä¼°èŠ‚ç‚¹è¿›å…¥äººå·¥å®¡æ ¸
    workflow.add_edge("evaluate", "human_review")

    # å¾ªç¯é€»è¾‘ï¼šå¦‚æœäººå·¥å®¡æ ¸æœªé€šè¿‡ï¼Œåˆ™è¿”å›åˆ°åˆå§‹åˆ†æèŠ‚ç‚¹ï¼ˆæˆ–æ ¹æ®éœ€æ±‚è¿”å›åˆ°å…¶ä»–èŠ‚ç‚¹ï¼‰
    workflow.add_conditional_edges(
        "human_review",
        lambda state: "redo" if not state["human_approved"] else "end",
        {
            "redo": "analyze",  # è¿”å›åˆ°åˆå§‹åˆ†æèŠ‚ç‚¹è¿›è¡Œé‡æ–°æ€è€ƒ
            "end": END
        }
    )

    return workflow.compile()


if __name__ == "__main__":
    # åˆå§‹åŒ–ç¯å¢ƒå˜é‡ (è¯·åœ¨å®é™…è¿è¡Œå‰è®¾ç½®ä½ çš„API Key)
    # os.environ["DASHSCOPE_API_KEY"] = "YOUR_DASHSCOPE_QWEN_API_KEY"
    # os.environ["DASHSCOPE_API_KEY2"] = "YOUR_DASHSCOPE_DEEPSEEK_API_KEY"

    # åˆå§‹åŒ–å·¥ä½œæµ
    app = create_scheduling_graph()

    # å®šä¹‰åˆå§‹çŠ¶æ€æ•°æ®
    initial_state = {
        "current_datacenter_load_factor": 0.75,  # 75% è´Ÿè½½ç‡
        "predicted_green_energy_ratio": 0.5,  # 50% ç»¿ç”µå æ¯”
        "grid_carbon_intensity": 450.0,  # ç”µç½‘ç¢³æ’æ”¾å¼ºåº¦ 450 gCO2/kWh
        "target_pue": 1.3,  # ç›®æ ‡ PUE
        "energy_storage_soc_current_percent": 0.6,  # å‚¨èƒ½å½“å‰ 60% ç”µé‡
        "energy_storage_capacity_mwh": 100.0,  # å‚¨èƒ½æ€»å®¹é‡ 100 MWh
        "grid_stability_index": 0.8,  # ç”µç½‘ç¨³å®šæ€§è‰¯å¥½
        "energy_price_forecast_per_kwh": {
            "h0": 0.8, "h1": 0.75, "h2": 0.7, "h3": 0.65,
            "h4": 0.6, "h5": 0.7, "h6": 0.85, "h7": 0.9,
            "h8": 0.95, "h9": 1.0, "h10": 0.9, "h11": 0.8
        },
        "green_energy_allocation": {},
        "energy_storage_strategy": {},
        "migration_path": {},
        "llm_insights": "",
        "final_plan": {},
        "evaluation_report": None,  # åˆå§‹åŒ–ä¸º None
        "human_feedback": "",
        "human_approved": False,
        "messages": []
    }

    print("å¼€å§‹æ‰§è¡Œæ•°æ®ä¸­å¿ƒæ™ºèƒ½è°ƒåº¦å·¥ä½œæµ...")
    print("åˆå§‹çŠ¶æ€:")
    for key, value in initial_state.items():
        if key != "messages":
            print(f"  - {key}: {value}")
    print("=" * 60)

    # æ‰§è¡Œå·¥ä½œæµ
    result = app.invoke(initial_state)

    # è¾“å‡ºç»“æœ
    print("\n[æœ€ç»ˆç»¿ç”µåˆ†é…æ–¹æ¡ˆåŠä¸“å®¶å»ºè®®]")
    if "final_plan" in result and "green_energy_allocation_detail" in result["final_plan"]:
        print("ç»¿ç”µåˆ†é…ç»†åˆ™:")
        print(json.dumps(result["final_plan"]["green_energy_allocation_detail"], indent=2, ensure_ascii=False))

    if "final_plan" in result and "expert_advice_from_power_electronics_perspective" in result["final_plan"]:
        print("\nä¸“å®¶LLMå»ºè®® (ä¾§é‡ç”µåŠ›ç”µå­ä¼˜åŒ–):")
        print(result["final_plan"]["expert_advice_from_power_electronics_perspective"])

    if "evaluation_report" in result and result["evaluation_report"]:
        print("\nè‡ªåŠ¨è¯„ä¼°æŠ¥å‘Š:")
        print(result["evaluation_report"])

    print("\n[å…³é”®æ‰§è¡Œæ—¥å¿—]")
    for msg in result["messages"]:
        # ä¿®æ­£äº†åˆ¤æ–­æ¡ä»¶ï¼Œé¿å…åœ¨æ‰“å°æ—¥å¿—æ—¶é—æ¼è¯„ä¼°å¤±è´¥çš„ä¿¡æ¯
        if isinstance(msg,
                      AIMessage) and "å¤§æ¨¡å‹æ´å¯Ÿ (ç”µåŠ›ç”µå­ä¼˜åŒ–è§†è§’)" not in msg.content and "è¯„ä¼°æ¨¡å‹è°ƒç”¨å¤±è´¥" not in msg.content:
            print(f"AIMessage: {msg.content}")
        elif isinstance(msg, HumanMessage):
            print(f"HumanMessage: {msg.content}")

    if result["human_approved"]:
        print("\næœ€ç»ˆæ–¹æ¡ˆå·²é€šè¿‡äººå·¥å®¡æ ¸ã€‚")
    else:
        print(f"\næœ€ç»ˆæ–¹æ¡ˆæœªé€šè¿‡äººå·¥å®¡æ ¸ã€‚åé¦ˆæ„è§: {result.get('human_feedback', 'æ— å…·ä½“æ„è§')}")